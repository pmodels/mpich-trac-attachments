<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
<HEAD>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=us-ascii">
<META NAME="Generator" CONTENT="MS Exchange Server version 6.5.7036.0">
<TITLE>RE: [mpich2-maint] #403: mpiexec kills the remote login shell</TITLE>
</HEAD>
<BODY>
<!-- Converted from text/plain format -->

<P><FONT SIZE=2>&nbsp;Hi,<BR>
&nbsp; The debug outputs look normal (the problem could be with the part of the code at mpiexec exit() which has no dbg statements). I have added this to our bug tracking list.<BR>
&nbsp; Meanwhile,<BR>
<BR>
#&nbsp; Can you send us your &quot;.smpd&quot; config file ?<BR>
#&nbsp; Did you modify the MPICH2 code to run on Korbet&nbsp; (Please send us&nbsp; your configure command &amp; any env settings set to&nbsp; configure/make MPICH2)?<BR>
<BR>
Regards,<BR>
Jayesh<BR>
<BR>
-----Original Message-----<BR>
From: owner-mpich2-bugs@mcs.anl.gov [<A HREF="mailto:owner-mpich2-bugs@mcs.anl.gov">mailto:owner-mpich2-bugs@mcs.anl.gov</A>] On Behalf Of mpich2<BR>
Sent: Thursday, February 05, 2009 2:11 PM<BR>
To: undisclosed-recipients:<BR>
Subject: [mpich2-maint] #403: FW: [mpich-discuss] mpiexec kills the remote login shell<BR>
<BR>
---------------------------------------------------+--------------------<BR>
---------------------------------------------------+----<BR>
&nbsp;Reporter:&nbsp; &quot;Jayesh Krishna&quot; &lt;jayesh@mcs.anl.gov&gt;&nbsp; |&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Type:&nbsp; bug&nbsp;&nbsp;<BR>
&nbsp;&nbsp; Status:&nbsp; new&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |&nbsp;&nbsp;&nbsp; Priority:&nbsp; major<BR>
Milestone:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |&nbsp;&nbsp; Component:&nbsp; mpich2<BR>
---------------------------------------------------+--------------------<BR>
---------------------------------------------------+----<BR>
<BR>
<BR>
&nbsp;{{{<BR>
<BR>
<BR>
<BR>
&nbsp;&gt; -----Original Message-----<BR>
&nbsp;&gt; From: Yu-Cheng Chou [<A HREF="mailto:cycchou@ucdavis.edu">mailto:cycchou@ucdavis.edu</A>]&nbsp; &gt; Sent: Wednesday, February 04, 2009 2:32 PM&nbsp; &gt; To: Jayesh Krishna&nbsp; &gt; Cc: mpich-discuss@mcs.anl.gov&nbsp; &gt; Subject: Re: [mpich-discuss] mpiexec kills the remote login shell&nbsp; &gt;&nbsp; &gt; &gt;&nbsp; Hi,<BR>
&nbsp;&gt; &gt;&nbsp;&nbsp; Does smpd abort when you run your MPI job ?<BR>
&nbsp;&gt;<BR>
&nbsp;&gt; No.<BR>
&nbsp;&gt;<BR>
&nbsp;&gt; &gt;<BR>
&nbsp;&gt; &gt; Regards,<BR>
&nbsp;&gt; &gt; Jayesh<BR>
&nbsp;&gt; &gt;<BR>
&nbsp;&gt; &gt; -----Original Message-----<BR>
&nbsp;&gt; &gt; From: Yu-Cheng Chou [<A HREF="mailto:cycchou@ucdavis.edu">mailto:cycchou@ucdavis.edu</A>]&nbsp; &gt; &gt; Sent: Wednesday, February 04, 2009 1:56 PM&nbsp; &gt; &gt; To: Jayesh Krishna&nbsp; &gt; &gt; Cc: mpich-discuss@mcs.anl.gov&nbsp; &gt; &gt; Subject: Re: [mpich-discuss] mpiexec kills the remote login shell&nbsp; &gt; &gt;&nbsp; &gt; &gt; Hi&nbsp; &gt; &gt;&nbsp; &gt; &gt; I can cross-compile the program and then simply run the&nbsp; &gt; executable on&nbsp; &gt; &gt; Korebot with no errors.<BR>
&nbsp;&gt; &gt;<BR>
&nbsp;&gt; &gt;<BR>
&nbsp;&gt; &gt;&gt; Hi,<BR>
&nbsp;&gt; &gt;&gt;&nbsp; Can you try running (without mpiexec) a simple C program with&nbsp; &gt; &gt;&gt; exit(-1) on Korebot ?<BR>
&nbsp;&gt; &gt;&gt;<BR>
&nbsp;&gt; &gt;&gt; ========================================<BR>
&nbsp;&gt; &gt;&gt; #include &lt;stdlib.h&gt;<BR>
&nbsp;&gt; &gt;&gt; int main(int argc, char *argv[])<BR>
&nbsp;&gt; &gt;&gt; {<BR>
&nbsp;&gt; &gt;&gt;&nbsp;&nbsp;&nbsp;&nbsp; exit(-1);<BR>
&nbsp;&gt; &gt;&gt; }<BR>
&nbsp;&gt; &gt;&gt; ========================================<BR>
&nbsp;&gt; &gt;&gt;<BR>
&nbsp;&gt; &gt;&gt; Regards,<BR>
&nbsp;&gt; &gt;&gt; Jayesh<BR>
&nbsp;&gt; &gt;&gt; ________________________________<BR>
&nbsp;&gt; &gt;&gt; From: mpich-discuss-bounces@mcs.anl.gov&nbsp; &gt; &gt;&gt; [<A HREF="mailto:mpich-discuss-bounces@mcs.anl.gov">mailto:mpich-discuss-bounces@mcs.anl.gov</A>] On Behalf Of Jayesh&nbsp; &gt; &gt;&gt; Krishna&nbsp; &gt; &gt;&gt; Sent: Wednesday, February 04, 2009 1:04 PM&nbsp; &gt; &gt;&gt; To: 'Yu-Cheng Chou'<BR>
&nbsp;&gt; &gt;&gt; Cc: mpich-discuss@mcs.anl.gov<BR>
&nbsp;&gt; &gt;&gt; Subject: Re: [mpich-discuss] mpiexec kills the remote login shell&nbsp; &gt; &gt;&gt;&nbsp; &gt; &gt;&gt;&nbsp; Hi,<BR>
&nbsp;&gt; &gt;&gt;&nbsp;&nbsp; Can you also attach the corresponding smpd debug output ?<BR>
&nbsp;&gt; &gt;&gt;<BR>
&nbsp;&gt; &gt;&gt; Regards,<BR>
&nbsp;&gt; &gt;&gt; Jayesh<BR>
&nbsp;&gt; &gt;&gt;<BR>
&nbsp;&gt; &gt;&gt; -----Original Message-----<BR>
&nbsp;&gt; &gt;&gt; From: Yu-Cheng Chou [<A HREF="mailto:cycchou@ucdavis.edu">mailto:cycchou@ucdavis.edu</A>]&nbsp; &gt; &gt;&gt; Sent: Wednesday, February 04, 2009 1:02 PM&nbsp; &gt; &gt;&gt; To: Jayesh Krishna&nbsp; &gt; &gt;&gt; Cc: mpich-discuss@mcs.anl.gov&nbsp; &gt; &gt;&gt; Subject: Re: [mpich-discuss] mpiexec kills the remote login shell&nbsp; &gt; &gt;&gt;&nbsp; &gt; &gt;&gt; Hi,&nbsp; &gt; &gt;&gt;&nbsp; &gt; &gt;&gt; Firstly, the previously attached mpiexec verbose output is&nbsp; &gt; a wrong one.<BR>
&nbsp;&gt; &gt;&gt; I've attached the correct one to this email.<BR>
&nbsp;&gt; &gt;&gt;<BR>
&nbsp;&gt; &gt;&gt; Secondly, I want to point out that as long as mpiexec is initiated&nbsp; &gt; &gt;&gt; from Korebot to run a program, no matter it's a MPI or non-MPI&nbsp; &gt; &gt;&gt; program, no matter the program can be found or not, as soon as&nbsp; &gt; &gt;&gt; mpiexec is finished, the ssh connection to Korebot will be gone.<BR>
&nbsp;&gt; &gt;&gt;<BR>
&nbsp;&gt; &gt;&gt; Thank you<BR>
&nbsp;&gt; &gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt; Hi,<BR>
&nbsp;&gt; &gt;&gt;&gt;&nbsp;&nbsp; The mpiexec output shows the following error when<BR>
&nbsp;&gt; running hellow,<BR>
&nbsp;&gt; &gt;&gt;&gt; ==================<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt; Unable to exec 'hello' on korebot&nbsp; &gt; &gt;&gt;&gt;&nbsp; &gt; &gt;&gt;&gt; Error 2 - No such file or directory&nbsp; &gt; &gt;&gt;&gt;&nbsp; &gt; &gt;&gt;&gt; ==================&nbsp; &gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;&nbsp;&nbsp; Please provide the debug output of smpd (smpd -d 2&gt;&amp;1 | tee<BR>
&nbsp;&gt; &gt;&gt;&gt; smpd.out) along with mpiexec (mpiexec -verbose -n 2&nbsp; &gt; ./hellow 2&gt;&amp;1 |&nbsp; &gt; &gt;&gt;&gt; tee mpiexec.out).<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt; #&nbsp; Can you run simple C programs (without using mpiexec)&nbsp; &gt; on Korbet ?<BR>
&nbsp;&gt; &gt;&gt;&gt; #&nbsp; Is the ssh connection aborted when you run non-MPI programs&nbsp; &gt; &gt;&gt;&gt; (mpiexec -n 2&nbsp; &gt; &gt;&gt;&gt; hostname) ?<BR>
&nbsp;&gt; &gt;&gt;&gt; #&nbsp; Can you send us your &quot;.smpd&quot; config file ?<BR>
&nbsp;&gt; &gt;&gt;&gt; #&nbsp; Did you modify the MPICH2 code to run on Korbet&nbsp; &gt; (Please send us&nbsp; &gt; &gt;&gt;&gt; your configure command &amp; any env settings set to&nbsp; &gt; configure/make MPICH2)?<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt; Regards,<BR>
&nbsp;&gt; &gt;&gt;&gt; Jayesh<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt; ________________________________<BR>
&nbsp;&gt; &gt;&gt;&gt; From: mpich-discuss-bounces@mcs.anl.gov&nbsp; &gt; &gt;&gt;&gt; [<A HREF="mailto:mpich-discuss-bounces@mcs.anl.gov">mailto:mpich-discuss-bounces@mcs.anl.gov</A>] On Behalf Of Jayesh&nbsp; &gt; &gt;&gt;&gt; Krishna&nbsp; &gt; &gt;&gt;&gt; Sent: Wednesday, February 04, 2009 8:41 AM&nbsp; &gt; &gt;&gt;&gt; To: 'Yu-Cheng Chou'<BR>
&nbsp;&gt; &gt;&gt;&gt; Cc: mpich-discuss@mcs.anl.gov<BR>
&nbsp;&gt; &gt;&gt;&gt; Subject: Re: [mpich-discuss] mpiexec kills the remote login shell&nbsp; &gt; &gt;&gt;&gt;&nbsp; &gt; &gt;&gt;&gt;&nbsp; Hi,<BR>
&nbsp;&gt; &gt;&gt;&gt;&nbsp;&nbsp; I will take a look at the debug logs and get back to you.<BR>
&nbsp;&gt; &gt;&gt;&gt; Meanwhile, can you run simple C programs without using mpiexec on&nbsp; &gt; &gt;&gt;&gt; Korbet ?<BR>
&nbsp;&gt; &gt;&gt;&gt;&nbsp;&nbsp; MPICH2 currently does not support heterogeneous systems (So you<BR>
&nbsp;&gt; &gt;&gt;&gt; won't be able to run your MPI job across ARM &amp; other&nbsp; &gt; architectures).<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt; Regards,<BR>
&nbsp;&gt; &gt;&gt;&gt; Jayesh<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt; -----Original Message-----<BR>
&nbsp;&gt; &gt;&gt;&gt; From: Yu-Cheng Chou [<A HREF="mailto:cycchou@ucdavis.edu">mailto:cycchou@ucdavis.edu</A>]&nbsp; &gt; &gt;&gt;&gt; Sent: Tuesday, February 03, 2009 7:52 PM&nbsp; &gt; &gt;&gt;&gt; To: Jayesh Krishna&nbsp; &gt; &gt;&gt;&gt; Cc: mpich-discuss@mcs.anl.gov&nbsp; &gt; &gt;&gt;&gt; Subject: Re: [mpich-discuss] mpiexec kills the remote login shell&nbsp; &gt; &gt;&gt;&gt;&nbsp; &gt; &gt;&gt;&gt;&gt; # Can you run non-MPI programs using mpiexec (mpiexec -n&nbsp; &gt; 2 hostname) ?<BR>
&nbsp;&gt; &gt;&gt;&gt; Yes.<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt; # Can you compile and run the hello world program&nbsp; &gt; &gt;&gt;&gt;&gt; (examples/hellow.c) provided with MPICH2 (mpiexec -n 2 ./hellow)?<BR>
&nbsp;&gt; &gt;&gt;&gt; Yes.<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt; # How did you start smpd (the command used to start&nbsp; &gt; smpd) ? How did&nbsp; &gt; &gt;&gt;&gt;&gt; you run your MPI job (the command used to run your job)?<BR>
&nbsp;&gt; &gt;&gt;&gt; I have a &quot;.smpd&quot; file containing one line of information,&nbsp; &gt; which is&nbsp; &gt; &gt;&gt;&gt; &quot;phrase=123&quot;.<BR>
&nbsp;&gt; &gt;&gt;&gt; Thus, I started smpd using &quot;smpd -s&quot;.<BR>
&nbsp;&gt; &gt;&gt;&gt; Then I used &quot;mpiexec -n 1 hellow&quot; to run hellow on Korebot.<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt; # How did you find that mpiexec kills the sshd process (We&nbsp; &gt; &gt;&gt;&gt;&gt; typically ssh to unix machines and run mpiexec without&nbsp; &gt; any problems) ?<BR>
&nbsp;&gt; &gt;&gt;&gt; I logged in Korebot with two terminals.<BR>
&nbsp;&gt; &gt;&gt;&gt; &gt;From #1 terminal, I checked all the processes running on Korebot.<BR>
&nbsp;&gt; &gt;&gt;&gt; &gt;From #2 terminal, I started smpd and run hellow using&nbsp; &gt; the commands&nbsp; &gt; &gt;&gt;&gt; mentioned above.<BR>
&nbsp;&gt; &gt;&gt;&gt; After hellow was finished, the connection to Korebot via&nbsp; &gt; #2 terminal&nbsp; &gt; &gt;&gt;&gt; was closed.<BR>
&nbsp;&gt; &gt;&gt;&gt; &gt;From #1 terminal, I knew that the sshd process&nbsp; &gt; associated with #2&nbsp; &gt; &gt;&gt;&gt; &gt;terminal&nbsp; &gt; &gt;&gt;&gt; was gone.<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt;&nbsp; Can you run smpd/mpiexec in debug mode and provide us with the&nbsp; &gt; &gt;&gt;&gt;&gt; outputs (smpd -d / mpiexec -n 2 -verbose hostname) ?<BR>
&nbsp;&gt; &gt;&gt;&gt; The first attached text file is the output from running hellow in&nbsp; &gt; &gt;&gt;&gt; mpiexec's verbose mode.<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt; There is another issue.<BR>
&nbsp;&gt; &gt;&gt;&gt; This time, I used two machines. One is Korebot as&nbsp; &gt; mentioned above,&nbsp; &gt; &gt;&gt;&gt; and the other is a laptop running Ubuntu Linux OS.<BR>
&nbsp;&gt; &gt;&gt;&gt; I started smpd with the same &quot;.smpd&quot; file and command as&nbsp; &gt; mentioned&nbsp; &gt; &gt;&gt;&gt; above both on Korebot and the lap top.<BR>
&nbsp;&gt; &gt;&gt;&gt; There is a machine file called &quot;hostfile&quot; on Korebot. The file&nbsp; &gt; &gt;&gt;&gt; contains the following information about the name of the&nbsp; &gt; two machines.<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt; korebot<BR>
&nbsp;&gt; &gt;&gt;&gt; shrimp<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt; Then from Korebot, I ran cpi using the following command.<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt; mpiexec -machinefile ./hostfile -verbose -n 2 cpi&nbsp; &gt; &gt;&gt;&gt;&nbsp; &gt; &gt;&gt;&gt;&nbsp; &gt; &gt;&gt;&gt; But the value of pi is a huge number. I think it is related to&nbsp; &gt; &gt;&gt;&gt; &quot;double type variables&quot; being transferred between&nbsp; &gt; processes running&nbsp; &gt; &gt;&gt;&gt; on an ARM-based Linux and a general Linux machines.<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt; The second attached text file is the output from running cpi in&nbsp; &gt; &gt;&gt;&gt; mpiexec's verbose mode.<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt; I am cross-compiling mpich2-1.0.8 with smpd for Khepera&nbsp; &gt; III mobile&nbsp; &gt; &gt;&gt;&gt;&gt; robot.<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt; This mobile robot has a Korebot board which is an ARM-based&nbsp; &gt; &gt;&gt;&gt;&gt; computer with a Linux operating system.<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt; The cross-compilation was fine.<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt; Firstly, I logged in to Korebot through ssh.<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt; Secondly, I started smpd.<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt; Thirdly, I ran mpiexec to execute an MPI program (cpi)&nbsp; &gt; that comes&nbsp; &gt; &gt;&gt;&gt;&gt; with the package.<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt; The result was correct, but when mpiexec was finished, the ssh&nbsp; &gt; &gt;&gt;&gt;&gt; connection to the Korebot was closed.<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt; I found that mpiexec kills the sshd process through which I was&nbsp; &gt; &gt;&gt;&gt;&gt; remotely connected to Korebot.<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt; I've been looking for the cause, but still have not&nbsp; &gt; found any clues.<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt; Could you give me any ideas to solve this problem?<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt; Thank you,<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt; Yu-Cheng<BR>
&nbsp;&gt; &gt;&gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;&gt;<BR>
&nbsp;&gt; &gt;&gt;<BR>
&nbsp;&gt; &gt;<BR>
&nbsp;&gt;<BR>
&nbsp;}}}<BR>
<BR>
<BR>
--<BR>
Ticket URL: &lt;<A HREF="https://trac.mcs.anl.gov/projects/mpich2/ticket/403">https://trac.mcs.anl.gov/projects/mpich2/ticket/403</A>&gt;<BR>
</FONT>
</P>

</BODY>
</HTML>